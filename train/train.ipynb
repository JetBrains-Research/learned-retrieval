{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. completion, context_positive, context_negative\n",
    "2. completion, context_positive, [context_negatives]\n",
    "3. isolate samples from the same repo, but different completion file\n",
    "4. isolate samples from the same repo, same completion file, but different content(line_type+line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "class CompletionContextDataset(Dataset):\n",
    "    def __init__(self, input_data, tokenizer, max_length=128, test=False):\n",
    "        self.data = []\n",
    "\n",
    "        for item in input_data:\n",
    "            completion = item['completion_content']\n",
    "            em = np.asarray(item['EMs'])\n",
    "            context_files = np.asarray(item['context_files'])\n",
    "\n",
    "            positive_indices = np.where(em == 1)[0]\n",
    "            negative_indices = np.where(em == 0)[0]\n",
    "\n",
    "            positive_contexts = context_files[positive_indices]\n",
    "            negative_contexts = context_files[negative_indices]\n",
    "\n",
    "            if test:\n",
    "                for p in positive_contexts:\n",
    "                    self.data.append((completion, p[0]['content']))\n",
    "                for n in positive_contexts:\n",
    "                    self.data.append((completion, n[0]['content']))\n",
    "            else:\n",
    "                for p in positive_contexts:\n",
    "                    for n in negative_contexts:\n",
    "                        self.data.append((completion, p[0]['content'], n[0]['content']))\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx, ):\n",
    "        completion, positive_context, negative_context = self.data[idx]\n",
    "\n",
    "        completion_encoding = self.tokenizer(completion, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        positive_context_encoding = self.tokenizer(positive_context, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        negative_context_encoding = self.tokenizer(negative_context, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        \n",
    "        return completion_encoding, positive_context_encoding, negative_context_encoding\n",
    "        # return completion, positive_context, negative_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kolomyttseva/Git/learned-retrieval/jsonl/lcdfg1ta/generated_data/pred_medium_context_True_5.jsonl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "project_name = 'lca-eval'\n",
    "run_id = 'lcdfg1ta'\n",
    "local_path = '/home/kolomyttseva/Git/learned-retrieval/jsonl'\n",
    "\n",
    "folder_path = f'{local_path}/{run_id}/generated_data'\n",
    "\n",
    "file_name = os.listdir(folder_path)[0]\n",
    "path = f'{folder_path}/{file_name}'\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 32 42\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_data, val_data = train_test_split(data, test_size=0.1)\n",
    "\n",
    "train_dataset = CompletionContextDataset(train_data, tokenizer)\n",
    "val_dataset = CompletionContextDataset(val_data, tokenizer)\n",
    "\n",
    "print(len(data), len(train_dataset), len(val_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "# next(iter(train_loader))[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.similarity = nn.CosineSimilarity(dim=-1, eps=1e-7)\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, completion, positive_context, negative_context):\n",
    "        positive_score = torch.abs(self.similarity(completion, positive_context))\n",
    "        negative_score = self.similarity(completion, negative_context)\n",
    "        # print(f'Positive Score: {positive_score}, Negative Score: {negative_score}')\n",
    "\n",
    "        score_difference = positive_score - negative_score\n",
    "        \n",
    "        target = torch.ones_like(score_difference)\n",
    "        loss = self.mse_loss(score_difference, target)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiEncoderModel(nn.Module):\n",
    "    def __init__(self, model_name):\n",
    "        super(BiEncoderModel, self).__init__()\n",
    "        self.completion_encoder = BertModel.from_pretrained(model_name)\n",
    "        self.context_encoder = BertModel.from_pretrained(model_name)\n",
    "\n",
    "    def forward(self, completion, positive_context, negative_context):\n",
    "        completion_embeds = self.completion_encoder(**completion).pooler_output\n",
    "        positive_context_embeds = self.context_encoder(**positive_context).pooler_output\n",
    "        negative_context_embeds = self.context_encoder(**negative_context).pooler_output\n",
    "\n",
    "        return completion_embeds, positive_context_embeds, negative_context_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = BiEncoderModel('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion, _, _ = train_dataset[0]\n",
    "# print(completion['input_ids'][0].shape)\n",
    "\n",
    "# completion_encoder = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "# completion_embeds = completion_encoder(**completion.to(device))\n",
    "\n",
    "# print(completion_embeds.last_hidden_state[0].shape)\n",
    "# print(completion_embeds.pooler_output[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0    \n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        completion, positive_context, negative_context = batch\n",
    "        completion = {k: v.squeeze().to(device) for k, v in completion.items()}\n",
    "        positive_context = {k: v.squeeze().to(device) for k, v in positive_context.items()}\n",
    "        negative_context = {k: v.squeeze().to(device) for k, v in negative_context.items()}\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        completion_embeds, positive_context_embeds, negative_context_embeds = model(completion, positive_context, negative_context)\n",
    "        loss = criterion(completion_embeds, positive_context_embeds, negative_context_embeds)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        print(f'Train Batch {batch_idx+1}/{len(dataloader)}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    print(f'Average Training Loss: {average_loss:.4f}')\n",
    "    return average_loss\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            completion, positive_context, negative_context = batch\n",
    "            completion = {k: v.squeeze().to(device) for k, v in completion.items()}\n",
    "            positive_context = {k: v.squeeze().to(device) for k, v in positive_context.items()}\n",
    "            negative_context = {k: v.squeeze().to(device) for k, v in negative_context.items()}\n",
    "            \n",
    "            completion_embeds, positive_context_embeds, negative_context_embeds = model(completion, positive_context, negative_context)\n",
    "            loss = criterion(completion_embeds, positive_context_embeds, negative_context_embeds)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            print(f'Validation Batch {batch_idx+1}/{len(dataloader)}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    average_loss = total_loss / len(dataloader)\n",
    "    print(f'Average Validation Loss: {average_loss:.4f}')\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train Batch 1/4, Loss: 0.9005\n",
      "Train Batch 2/4, Loss: 0.6546\n",
      "Train Batch 3/4, Loss: 1.1035\n",
      "Train Batch 4/4, Loss: 1.0272\n",
      "Average Training Loss: 0.9215\n",
      "Validation Batch 1/6, Loss: 0.9790\n",
      "Validation Batch 2/6, Loss: 0.9948\n",
      "Validation Batch 3/6, Loss: 0.9896\n",
      "Validation Batch 4/6, Loss: 0.9950\n",
      "Validation Batch 5/6, Loss: 0.9948\n",
      "Validation Batch 6/6, Loss: 1.0002\n",
      "Average Validation Loss: 0.9922\n",
      "Epoch 1 completed, Training Loss: 0.9215, Validation Loss: 0.9922\n",
      "Epoch 2/5\n",
      "Train Batch 1/4, Loss: 0.9935\n",
      "Train Batch 2/4, Loss: 0.3662\n",
      "Train Batch 3/4, Loss: 0.9348\n",
      "Train Batch 4/4, Loss: 1.0174\n",
      "Average Training Loss: 0.8280\n",
      "Validation Batch 1/6, Loss: 0.9989\n",
      "Validation Batch 2/6, Loss: 0.9987\n",
      "Validation Batch 3/6, Loss: 0.9351\n",
      "Validation Batch 4/6, Loss: 0.6791\n",
      "Validation Batch 5/6, Loss: 0.8074\n",
      "Validation Batch 6/6, Loss: 0.9991\n",
      "Average Validation Loss: 0.9030\n",
      "Epoch 2 completed, Training Loss: 0.8280, Validation Loss: 0.9030\n",
      "Epoch 3/5\n",
      "Train Batch 1/4, Loss: 1.0042\n",
      "Train Batch 2/4, Loss: 0.8125\n",
      "Train Batch 3/4, Loss: 0.9275\n",
      "Train Batch 4/4, Loss: 0.8864\n",
      "Average Training Loss: 0.9076\n",
      "Validation Batch 1/6, Loss: 0.8947\n",
      "Validation Batch 2/6, Loss: 0.7891\n",
      "Validation Batch 3/6, Loss: 0.7886\n",
      "Validation Batch 4/6, Loss: 0.8947\n",
      "Validation Batch 5/6, Loss: 0.7886\n",
      "Validation Batch 6/6, Loss: 0.5769\n",
      "Average Validation Loss: 0.7888\n",
      "Epoch 3 completed, Training Loss: 0.9076, Validation Loss: 0.7888\n",
      "Epoch 4/5\n",
      "Train Batch 1/4, Loss: 0.8975\n",
      "Train Batch 2/4, Loss: 0.9977\n",
      "Train Batch 3/4, Loss: 0.8104\n",
      "Train Batch 4/4, Loss: 0.6802\n",
      "Average Training Loss: 0.8465\n",
      "Validation Batch 1/6, Loss: 0.6360\n",
      "Validation Batch 2/6, Loss: 0.7571\n",
      "Validation Batch 3/6, Loss: 0.7566\n",
      "Validation Batch 4/6, Loss: 0.9989\n",
      "Validation Batch 5/6, Loss: 0.7569\n",
      "Validation Batch 6/6, Loss: 0.9991\n",
      "Average Validation Loss: 0.8174\n",
      "Epoch 4 completed, Training Loss: 0.8465, Validation Loss: 0.8174\n",
      "Epoch 5/5\n",
      "Train Batch 1/4, Loss: 0.6070\n",
      "Train Batch 2/4, Loss: 0.9780\n",
      "Train Batch 3/4, Loss: 0.1315\n",
      "Train Batch 4/4, Loss: 0.0557\n",
      "Average Training Loss: 0.4431\n",
      "Validation Batch 1/6, Loss: 0.0199\n",
      "Validation Batch 2/6, Loss: 0.0478\n",
      "Validation Batch 3/6, Loss: 0.0393\n",
      "Validation Batch 4/6, Loss: 0.0389\n",
      "Validation Batch 5/6, Loss: 0.0294\n",
      "Validation Batch 6/6, Loss: 0.0578\n",
      "Average Validation Loss: 0.0389\n",
      "Epoch 5 completed, Training Loss: 0.4431, Validation Loss: 0.0389\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)\n",
    "criterion = ContrastiveLoss()\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "    print(f'Epoch {epoch+1} completed, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
